{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw4uWIGnMyq8",
        "outputId": "dd260157-536e-42c2-ca98-303d0f51371c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stusents Records:\n",
            "1 - Rahul Sharma (Bangalore) -> Age 21\n",
            "2 - Priya Singh (Delhi) -> Age 22\n",
            "3 - Aman Kumar (Hyderabad) -> Age 20\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "json_data = '''\n",
        "[\n",
        "  { \"id\": 1, \"name\": \"Rahul Sharma\", \"age\": 21, \"city\": \"Bangalore\" },\n",
        "  { \"id\": 2, \"name\": \"Priya Singh\", \"age\": 22, \"city\": \"Delhi\" },\n",
        "  { \"id\": 3, \"name\": \"Aman Kumar\", \"age\": 20, \"city\": \"Hyderabad\" }\n",
        "]\n",
        "'''\n",
        "\n",
        "students = json.loads(json_data)\n",
        "\n",
        "print(\"Stusents Records:\")\n",
        "for s in students:\n",
        "  print(f\"{s['id']} - {s['name']} ({s['city']}) -> Age {s['age']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_data = '''\n",
        "\n",
        "[\n",
        "\n",
        "  { \"id\": 1, \"name\": \"Rahul Sharma\", \"age\": 21, \"city\": \"Bangalore\" },\n",
        "\n",
        "  { \"id\": 2, \"name\": \"Priya Singh\", \"age\": 22, \"city\": \"Delhi\" }\n",
        "\n",
        "]\n",
        "\n",
        "'''\n",
        "\n",
        "students = json.loads(json_data)\n",
        "\n",
        "new_student= {\"id\": 3, \"name\": \"Aman Kumar\" ,\"age\": 20,\"city\": \"Hyderabad\"}\n",
        "\n",
        "students.append(new_student)\n",
        "\n",
        "for s in students:\n",
        "  if s[\"id\"] ==1:\n",
        "    s[\"city\"] ==\"Pune\"\n",
        "\n",
        "updated_json = json.dumps(students, indent=2)\n",
        "\n",
        "print(\"Updated JSON Data:\\n\",updated_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7BGUakgWvkY",
        "outputId": "e6a875e0-a771-4b07-ed93-1b6faba0e4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated JSON Data:\n",
            " [\n",
            "  {\n",
            "    \"id\": 1,\n",
            "    \"name\": \"Rahul Sharma\",\n",
            "    \"age\": 21,\n",
            "    \"city\": \"Bangalore\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 2,\n",
            "    \"name\": \"Priya Singh\",\n",
            "    \"age\": 22,\n",
            "    \"city\": \"Delhi\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 3,\n",
            "    \"name\": \"Aman Kumar\",\n",
            "    \"age\": 20,\n",
            "    \"city\": \"Hyderabad\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Employee-Analysis\").getOrCreate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK0mfbQwpk4U",
        "outputId": "485767c6-866a-4dc0-bf46-22590ce0bd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "csv_data = \"\"\"id,name,department,salary\n",
        "1,Rahul Sharma,IT,55000\n",
        "2,Priya Singh,HR,60000\n",
        "3,Aman Kumar,Finance,48000\n",
        "4,Sneha Reddy,Marketing,52000\n",
        "5,Arjun Mehta,IT,75000\n",
        "6,Divya Nair,Finance,67000\n",
        "\"\"\"\n",
        "\n",
        "with open(\"employees.csv\",\"w\") as f:\n",
        "  f.write(csv_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "uV80oSvDp2CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"employees.csv\",header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv0XRzMWqqah",
        "outputId": "356a66fd-2567-4f43-f17c-f2b315988178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+----------+------+\n",
            "| id|        name|department|salary|\n",
            "+---+------------+----------+------+\n",
            "|  1|Rahul Sharma|        IT| 55000|\n",
            "|  2| Priya Singh|        HR| 60000|\n",
            "|  3|  Aman Kumar|   Finance| 48000|\n",
            "|  4| Sneha Reddy| Marketing| 52000|\n",
            "|  5| Arjun Mehta|        IT| 75000|\n",
            "|  6|  Divya Nair|   Finance| 67000|\n",
            "+---+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation**\n",
        "# üìù Key Points about Transformations\n",
        "\n",
        "* **Lazy Execution**:\n",
        "  Spark doesn‚Äôt run transformations right away. Instead, it builds a **logical plan** (a DAG ‚Äì Directed Acyclic Graph).\n",
        "  The computation only runs when an **action** (like `.show()` or `.count()`) is called.\n",
        "\n",
        "* **Return Type**:\n",
        "  A transformation always returns a **new DataFrame or RDD**. It does **not modify the existing one**.\n",
        "\n",
        "* **Two Types of Transformations**:\n",
        "\n",
        "  1. **Narrow Transformations** ‚Üí Each input partition contributes to only one output partition.\n",
        "     (e.g., `map()`, `filter()`, `select()`)\n",
        "  2. **Wide Transformations** ‚Üí Data is shuffled across partitions.\n",
        "     (e.g., `groupBy()`, `join()`)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4GmXHvT6w83E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"name\",\"salary\").show()\n",
        "\n",
        "df.filter(df[\"salary\"] > 60000).show()\n",
        "\n",
        "df.orderBy(df[\"salary\"].desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV7rjvRmwuwA",
        "outputId": "1d383624-90eb-4bc2-b9ad-64d331eacfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|        name|salary|\n",
            "+------------+------+\n",
            "|Rahul Sharma| 55000|\n",
            "| Priya Singh| 60000|\n",
            "|  Aman Kumar| 48000|\n",
            "| Sneha Reddy| 52000|\n",
            "| Arjun Mehta| 75000|\n",
            "|  Divya Nair| 67000|\n",
            "+------------+------+\n",
            "\n",
            "+---+-----------+----------+------+\n",
            "| id|       name|department|salary|\n",
            "+---+-----------+----------+------+\n",
            "|  5|Arjun Mehta|        IT| 75000|\n",
            "|  6| Divya Nair|   Finance| 67000|\n",
            "+---+-----------+----------+------+\n",
            "\n",
            "+---+------------+----------+------+\n",
            "| id|        name|department|salary|\n",
            "+---+------------+----------+------+\n",
            "|  5| Arjun Mehta|        IT| 75000|\n",
            "|  6|  Divya Nair|   Finance| 67000|\n",
            "|  2| Priya Singh|        HR| 60000|\n",
            "|  1|Rahul Sharma|        IT| 55000|\n",
            "|  4| Sneha Reddy| Marketing| 52000|\n",
            "|  3|  Aman Kumar|   Finance| 48000|\n",
            "+---+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aggregation**\n",
        "\n",
        "\n",
        "What is Aggregation?\n",
        "\n",
        "* An operation that **groups data** and applies a **summary function** (like sum, avg, count, min, max).\n",
        "* Used to answer questions like:\n",
        "\n",
        "  * *‚ÄúWhat is the average salary per department?‚Äù*\n",
        "  * *‚ÄúHow many employees are in each department?‚Äù*\n",
        "  * *‚ÄúWhat is the highest salary in Finance?‚Äù*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yFWz0HsS5Uxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"department\").avg(\"salary\").show()\n",
        "\n",
        "df.groupBy(\"department\").max(\"salary\").show()\n",
        "\n",
        "df.groupBy(\"department\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzA9iOy76XNr",
        "outputId": "ac740181-508a-43b2-f4cf-31ca4beaad30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|department|avg(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|    60000.0|\n",
            "|   Finance|    57500.0|\n",
            "| Marketing|    52000.0|\n",
            "|        IT|    65000.0|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|department|max(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|      60000|\n",
            "|   Finance|      67000|\n",
            "| Marketing|      52000|\n",
            "|        IT|      75000|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----+\n",
            "|department|count|\n",
            "+----------+-----+\n",
            "|        HR|    1|\n",
            "|   Finance|    2|\n",
            "| Marketing|    1|\n",
            "|        IT|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createReplaceTempView(\"employees\")\n",
        "spark.sql(\"SELECT department, AVG (salary) as avg_salary FROM employees GROUP BY department\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "hDkwZExf8Wx0",
        "outputId": "acfc4ac3-e316-46db-bc75-d476c3af657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'createReplaceTempView'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-320320766.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employees\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT department, AVG (salary) as avg_salary FROM employees GROUP BY department\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3125\u001b[0m         \"\"\"\n\u001b[1;32m   3126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   3128\u001b[0m                 \u001b[0;34m\"'%s' object has no attribute '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'createReplaceTempView'"
          ]
        }
      ]
    }
  ]
}