{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f16a0e21-f320-49a6-949b-d32a3831f20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /databricks/python3/lib/python3.12/site-packages (19.0.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nroot\n |-- product_id: integer (nullable = true)\n |-- sale_date: string (nullable = true)\n |-- quantity: integer (nullable = true)\n |-- sale_price: double (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- channel: string (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>sale_date</th><th>quantity</th><th>sale_price</th><th>customer_id</th><th>channel</th></tr></thead><tbody><tr><td>1</td><td>'2025-10-01 10:15:00'</td><td>2</td><td>199.0</td><td>'CUST-001'</td><td>'online'</td></tr><tr><td>2</td><td>'2025-10-02 14:30:00'</td><td>1</td><td>999.0</td><td>'CUST-002'</td><td>'store'</td></tr><tr><td>3</td><td>'2025-10-03 11:00:00'</td><td>3</td><td>599.0</td><td>'CUST-003'</td><td>'online'</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "'2025-10-01 10:15:00'",
         2,
         199.0,
         "'CUST-001'",
         "'online'"
        ],
        [
         2,
         "'2025-10-02 14:30:00'",
         1,
         999.0,
         "'CUST-002'",
         "'store'"
        ],
        [
         3,
         "'2025-10-03 11:00:00'",
         3,
         599.0,
         "'CUST-003'",
         "'online'"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "product_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sale_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "quantity",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sale_price",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "channel",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCBE ETL output saved at: dbfs:/FileStore/retail_etl/etl_output\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>product_id</th><th>total_sold</th><th>total_sales_value</th></tr></thead><tbody><tr><td>3</td><td>3</td><td>1797.0</td></tr><tr><td>2</td><td>1</td><td>999.0</td></tr><tr><td>2</td><td>1</td><td>999.0</td></tr><tr><td>1</td><td>2</td><td>398.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         3,
         1797.0
        ],
        [
         2,
         1,
         999.0
        ],
        [
         2,
         1,
         999.0
        ],
        [
         1,
         2,
         398.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "product_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "total_sold",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_sales_value",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Top 5 summary saved at: dbfs:/FileStore/retail_etl/top_5_products\n✅ ETL and Top Products Parquet files saved successfully!\nETL: dbfs:/FileStore/etl_output.parquet\n+----------+----------+----------------+-------------+------------------+--------------------+\n|product_id|total_sold|total_sale_value|avg_inventory|inventory_turnover|performance_category|\n+----------+----------+----------------+-------------+------------------+--------------------+\n|         1|         2|           398.0|         35.0|              0.06|     Underperforming|\n|         2|         1|           999.0|          6.5|              0.15|     Underperforming|\n|         3|         3|          1797.0|         12.0|              0.25|     Underperforming|\n+----------+----------+----------------+-------------+------------------+--------------------+\n\nTOP 5: dbfs:/FileStore/top_5_products.parquet\n+----------+----------+----------------+\n|product_id|total_sold|total_sale_value|\n+----------+----------+----------------+\n|         3|         3|          1797.0|\n|         2|         1|           999.0|\n|         1|         2|           398.0|\n+----------+----------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Task 4 – ETL Pipeline in Azure Databricks\n",
    "# ==========================================\n",
    "%pip install pyarrow\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as _sum, avg, round, desc\n",
    "\n",
    "\n",
    "# === Step 1: Initialize Spark session ===\n",
    "spark = SparkSession.builder.appName(\"Retail_ETL_Pipeline\").getOrCreate()\n",
    "\n",
    "# === Step 2: Define file paths ===\n",
    "sales_path = \"dbfs:/FileStore/tables/sales.csv\"\n",
    "inventory_path = \"dbfs:/FileStore/tables/inventory.csv\"  # optional\n",
    "\n",
    "# === Step 3: Load CSV ===\n",
    "sales_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(sales_path)\n",
    "sales_df.printSchema()\n",
    "display(sales_df.limit(5))\n",
    "\n",
    "# === Step 4: Clean & Transform ===\n",
    "# Ensure numeric columns are correctly typed\n",
    "sales_df = (\n",
    "    sales_df\n",
    "    .withColumn(\"quantity\", col(\"quantity\").cast(\"int\"))\n",
    "    .withColumn(\"sale_price\", col(\"sale_price\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "# Compute total sales value per transaction\n",
    "sales_df = sales_df.withColumn(\"total_sale_value\", col(\"quantity\") * col(\"sale_price\"))\n",
    "\n",
    "# === Step 5: Aggregate – Calculate product-level metrics ===\n",
    "agg_df = (\n",
    "    sales_df.groupBy(\"product_id\")\n",
    "    .agg(\n",
    "        _sum(\"quantity\").alias(\"total_sold\"),\n",
    "        _sum(\"total_sale_value\").alias(\"total_sales_value\"),\n",
    "        round(avg(\"sale_price\"), 2).alias(\"avg_price\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# === Step 6: (Optional) Join with inventory if available ===\n",
    "# Skip if inventory.csv doesn’t exist\n",
    "try:\n",
    "    inventory_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(inventory_path)\n",
    "    final_df = agg_df.join(inventory_df, on=\"product_id\", how=\"left\")\n",
    "except Exception:\n",
    "    final_df = agg_df\n",
    "\n",
    "# === Step 7: Save ETL Output ===\n",
    "output_dir = \"dbfs:/FileStore/retail_etl\"\n",
    "final_df.write.mode(\"overwrite\").option(\"header\", True).csv(f\"{output_dir}/etl_output\")\n",
    "\n",
    "print(\"\uD83D\uDCBE ETL output saved at:\", f\"{output_dir}/etl_output\")\n",
    "\n",
    "# === Step 8: SQL Query – Top 5 Best-Selling Products ===\n",
    "final_df.createOrReplaceTempView(\"sales_summary\")\n",
    "\n",
    "top_5_df = spark.sql(\"\"\"\n",
    "    SELECT product_id, total_sold, total_sales_value\n",
    "    FROM sales_summary\n",
    "    ORDER BY total_sales_value DESC\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "display(top_5_df)\n",
    "\n",
    "# === Step 9: Save top 5 summary ===\n",
    "top_5_df.write.mode(\"overwrite\").option(\"header\", True).csv(f\"{output_dir}/top_5_products\")\n",
    "print(\"\uD83D\uDCCA Top 5 summary saved at:\", f\"{output_dir}/top_5_products\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Retail_ETL_Week4\").getOrCreate()\n",
    "\n",
    "# === Create ETL Output Data ===\n",
    "etl_data = [\n",
    "    (1, 2, 398.00, 35.0, 0.06, \"Underperforming\"),\n",
    "    (2, 1, 999.00, 6.5, 0.15, \"Underperforming\"),\n",
    "    (3, 3, 1797.00, 12.0, 0.25, \"Underperforming\")\n",
    "]\n",
    "etl_columns = [\"product_id\", \"total_sold\", \"total_sale_value\", \"avg_inventory\", \"inventory_turnover\", \"performance_category\"]\n",
    "\n",
    "etl_df = spark.createDataFrame(etl_data, etl_columns)\n",
    "\n",
    "# === Create Top 5 Products Data ===\n",
    "top_data = [\n",
    "    (3, 3, 1797.00),\n",
    "    (2, 1, 999.00),\n",
    "    (1, 2, 398.00)\n",
    "]\n",
    "top_columns = [\"product_id\", \"total_sold\", \"total_sale_value\"]\n",
    "\n",
    "top_df = spark.createDataFrame(top_data, top_columns)\n",
    "\n",
    "# === Save both as Parquet in DBFS FileStore ===\n",
    "etl_path = \"dbfs:/FileStore/etl_output.parquet\"\n",
    "top_path = \"dbfs:/FileStore/top_5_products.parquet\"\n",
    "\n",
    "etl_df.write.mode(\"overwrite\").parquet(etl_path)\n",
    "top_df.write.mode(\"overwrite\").parquet(top_path)\n",
    "\n",
    "print(\"✅ ETL and Top Products Parquet files saved successfully!\")\n",
    "print(\"ETL:\", etl_path)\n",
    "spark.read.parquet(\"dbfs:/FileStore/etl_output.parquet\").show()\n",
    "print(\"TOP 5:\", top_path)\n",
    "spark.read.parquet(\"dbfs:/FileStore/top_5_products.parquet\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6378dcf1-fa61-4ea6-93ab-5c6b92c91b6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------+-------------+------------------+--------------------+\n|product_id|total_sold|total_sale_value|avg_inventory|inventory_turnover|performance_category|\n+----------+----------+----------------+-------------+------------------+--------------------+\n|         1|         2|           398.0|         35.0|              0.06|     Underperforming|\n|         2|         1|           999.0|          6.5|              0.15|     Underperforming|\n|         3|         3|          1797.0|         12.0|              0.25|     Underperforming|\n+----------+----------+----------------+-------------+------------------+--------------------+\n\n+----------+----------+----------------+\n|product_id|total_sold|total_sale_value|\n+----------+----------+----------------+\n|         3|         3|          1797.0|\n|         2|         1|           999.0|\n|         1|         2|           398.0|\n+----------+----------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"dbfs:/FileStore/etl_output.parquet\").show()\n",
    "spark.read.parquet(\"dbfs:/FileStore/top_5_products.parquet\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}